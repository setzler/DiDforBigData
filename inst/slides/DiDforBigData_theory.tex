

\documentclass[usenames,dvipsnames]{beamer}
\usetheme{metropolis}

\usepackage{pgfpages}
%\setbeameroption{show notes on second screen}
\setbeameroption{hide notes}
%\setbeamertemplate{note page}{\insertnote}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amssymb}
\usepackage{pifont} 
\usepackage{esint}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{listings}
\usetikzlibrary{decorations.pathreplacing}
\usepackage{verbatim}
\usepackage{soul}

\setbeamertemplate{footline}
{
  \hbox{\begin{beamercolorbox}[wd=1\paperwidth,ht=2.25ex,dp=1ex,right]{framenumber}%
      \usebeamerfont{framenumber}\insertframenumber{} / \inserttotalframenumber\hspace*{2ex}
    \end{beamercolorbox}}%
  \vskip0pt%
}


\usepackage{appendixnumberbeamer}
 
%Information to be included in the title page:
\title{\fontsize{15}{0}\selectfont DiD for Big Data in R\\\vspace{0.1cm}\fontsize{12}{30}\selectfont  Theoretical Background}
\author{\fontsize{12}{30}\selectfont  Bradley Setzler, Penn State}
\institute{\fontsize{6}{6}\selectfont \vspace{0.5cm} \textit{This draft compiled on: \today} }
\date{ }
 
 
 \linespread{.8}
 
 
\begin{document}
 
\frame{
\titlepage
}
 
 
 
%\begin{frame}{Advantages of the DiD for Big Data Package in R}
%
%\url{https://github.com/setzler/DiDforBigData}
%
%\begin{itemize}
%\item[$\bullet$]  \textbf{Consistent Estimates:} Even in staggered-DiD designs, it provides the consistent point estimates and valid SEs. 
%\vspace{0.1cm}
%\item[$\bullet$]  \textbf{Transparency:} The simple plug-in formulas provided above are at the high-school level of math. There is no mystery about what the code is doing; it literally takes averages and variances, then adds/subtracts them.
%\vspace{0.1cm}
%\item[$\bullet$] \textbf{User-friendly:} The user only needs to provide the data in a standard data-frame format. It is easy to set the options for event range ($e$), base period ($b$), and  choice of control group ($\mathcal{C}$). It also provides pretty plots automatically.
%\vspace{0.1cm}
%\item[$\bullet$] \textbf{Big-data:} I wrote it natively in a big-data language.
%\begin{itemize}
%\item[-] My package successfully estimates DiD for \textbf{1 million unique individuals in  20 seconds on a single core}. 
%\item[-] The other packages in R require between 1 hour and $\infty$ hours to estimate DiD with 1 million individuals.
%\end{itemize}
%\vspace{0.1cm}
%\item[$\bullet$]  \textbf{Light-weight:} The complete package is less than 0.1 MB in size, so it can easily be transferred onto admin servers, via email, etc. Furthermore, it only has 1 dependency, data.table, which is a standard R package available on nearly any system.
%\end{itemize}
%
%\end{frame}

 

\begin{frame}{Notation and Identification (1/4)}
 
\vspace{-0.1cm}

\textbf{Notation and Definition of Treatment:}

\vspace{-0.05cm}

\begin{itemize}
\item[$\bullet$] $i$: unit of observation. 
\begin{itemize}
\item[$\rightarrow$]  We will often say ``individual".
\end{itemize}

\vspace{0.1cm}
\item[$\bullet$] $t$: calendar time. Sample time frame is $\mathcal{T}$.
\begin{itemize}
\item[$\rightarrow$] We will often say ``year".
\end{itemize}

\vspace{0.1cm}
\item[$\bullet$] $D_{i,t}$: indicator for currently receiving treatment.
\begin{itemize}
\item[$\rightarrow$] Permanent treatment: $D_{i,t} =1 \implies D_{i,t+1}=1,\; t \in \mathcal{T}$.
\end{itemize}

\vspace{0.1cm}
\item[$\bullet$] $G_i \equiv \min\{t: D_{i,t}=1\}$: time that $i$ first receives  treatment.
\begin{itemize}
\item[$\rightarrow$] We will often say ``cohort" or ``onset time".
\item[$\rightarrow$] If $i$ never receives treatment, we can write $G_i = \infty$. 
\item[$\rightarrow$] Note: $D_{i,t} \equiv 1\{t \geq G_i\}$.
\end{itemize}

\vspace{0.1cm}
\item[$\bullet$] $E_{i,t} \equiv (t - G_{i})$: time since first treatment. 
\begin{itemize}
\item[$\rightarrow$] We will often say ``event time".
\item[$\rightarrow$] Sometimes we will consider fixing an event time $e$ years after treatment versus $b$ years before treatment.
\end{itemize}

\vspace{0.1cm}
\item[$\bullet$] Potential outcomes: Let $Y_{i,t}(g)$ denote the outcome that is experienced if treated at $g$.

\vspace{0.1cm}
\item[$\bullet$] Observed outcome: $Y_{i,t} =   Y_{i,t}(\infty) + \sum_{g} 1\{G_i=g\} (Y_{i,t}(g) - Y_{i,t}(\infty))$.
\end{itemize}
 
\vspace{-0.05cm}

\end{frame}


\begin{frame}{Notation and Identification (2/4)}

\textbf{Goal: Identify ATT at an event time.} We assume throughout that the goal is to identify the average treatment effect on the treated (ATT) at event time $e$. Formally, we seek to identify,
\begin{equation} \notag
\textrm{ATT}_{e} \equiv   \mathbb{E}[Y_{i,t}({\color{blue} g}) - Y_{i,t}({\color{red} \infty}) | {\color{blue}E_{i,t}=e}]  
\end{equation}
The identification challenge is that $\mathbb{E}[ Y_{i,t}({\color{red}\infty}) | {\color{blue}E_{i,t}=e}] $ is a counterfactual object -- it is the average outcome that \textit{would have been experienced} by those receiving treatment for $e$ years  \textit{if they had not received treatment}.




\textbf{Decomposition into cohort-specific ATTs.} Define,
\begin{equation} \notag
\begin{aligned}
\textrm{ATT}_{g,e} & \equiv   \mathbb{E}[Y_{i,g+e}({\color{blue} g})- Y_{i,g+e}({\color{red}\infty}) | {\color{blue}G_i = g}]  \\
\omega_{g,e} & \equiv \mathbb{E}[G_i=g | E_{i,t}=e]
\end{aligned}
\end{equation}
where the cohort shares that have been treated at each event time ($\omega_{g,e}$) are observed. Rearranging terms,  
\begin{equation} \notag
\textrm{ATT}_{e} =  \sum_{g} \omega_{g,e} \textrm{ATT}_{g,e}
\end{equation}
Thus, given $e$, it is sufficient to identify  $\textrm{ATT}_{g,e}$, $\forall g \; \text{s.t.} \; \omega_{g,e}>0$.

\end{frame}


\begin{frame}{Notation and Identification (3/4)}

\textbf{Control Group:} Define a control group membership indicator ${\color{red} \mathcal{C}_{g,e}(G_i)}$. At a minimum,   $ {\color{red} \mathcal{C}_{g,e}(G_i)  {=} 1} \implies G_i > (g+e)$. We may further restrict ${\color{red} \mathcal{C}}$ based on context, e.g., some  consider the never-treated control group, ${\color{red} \mathcal{C}_{g,e}(G_i)}  {=}  1\{G_i  {=}  \infty\}$.

\textbf{Assumption 1: Parallel trends.}
\begin{equation} \notag
\begin{aligned}
 \exists b<0 \; \text{s.t.} &\quad \mathbb{E}[Y_{i,g+e}({\color{red} \infty}) - Y_{i,g+b}({\color{red} \infty}) | {\color{red} \mathcal{C}_{g,e}(G_i)  {=} 1}] 
\\ &\quad = \mathbb{E}[Y_{i,g+e}({\color{red} \infty}) - Y_{i,g+b}({\color{red} \infty}) | {\color{blue}G_i = g}], \; \forall e \geq 0
\end{aligned}
\end{equation}
This restricts the relationship between the treated group ${\color{blue}G_i = g}$ and the control group ${\color{red} \mathcal{C}_{g,e}(G_i) {=} 1}$: the change in average outcome for the treated group \textit{would have been the same in the absence of treatment} as that of the control group.

\textbf{Assumption 2: No anticipation.} 
\begin{equation} \notag
\exists b<0 \;\; \text{s.t.} \;\; \mathbb{E}[Y_{i,g+b}({\color{blue} g}) | {\color{blue} G_i = g }] = \mathbb{E}[Y_{i,g+b}({\color{red} \infty}) | {\color{blue} G_i = g }] , \;\; \forall g
\end{equation}
This restricts \textit{when} the treated cohorts respond to treatment. 

\textbf{Note:} Both assumptions need only hold for the event time $e$ and pre-period $b$ chosen by the researcher.
 
\end{frame}



\begin{frame}{Notation and Identification (4/4)}

\textbf{Difference-in-differences:} Define the population estimator,
\begin{equation} \notag 
\text{DiD}_{g,e} {\equiv}  \mathbb{E}[Y_{i,g+e} {-} Y_{i,g+b} | {\color{blue} G_i = g }] {-}
\mathbb{E}[Y_{i,g+e} {-} Y_{i,g+b} | {\color{red} \mathcal{C}_{g,e}(G_i)  {=} 1}]
\end{equation}
It depends only on observed outcomes, not counterfactuals.

\textbf{Impose parallel trends:}  By the parallel-trends assumption, we can replace the second expectation as follows:
\begin{equation} \notag 
\text{DiD}_{g,e} {\equiv}  \mathbb{E}[Y_{i,g+e} {-} Y_{i,g+b} | {\color{blue} G_i = g }] {-}
\mathbb{E}[Y_{i,g+e}({\color{red} \infty}) - Y_{i,g+b}({\color{red} \infty}) | {\color{blue}G_i = g}]
\end{equation}

\textbf{Impose no anticipation:} By the no-anticipation assumption, we can cancel out the two terms involving $Y_{i,g+b}$:
\begin{equation} \notag 
\text{DiD}_{g,e} \equiv  \mathbb{E}[Y_{i,g+e}  | {\color{blue} G_i = g }] -
\mathbb{E}[Y_{i,g+e}({\color{red} \infty})  | {\color{blue}G_i = g}]
=
\text{ATT}_{g,e}
\end{equation}

\vspace{-0.05cm}

Thus, we have proven that $\text{DiD}_{g,e}=\text{ATT}_{g,e}$ if the parallel-trends and no-anticipation assumptions hold for the pair $(g,e)$. 

\textbf{Result:} If  parallel-trends and no-anticipation hold $\forall g \; \text{s.t.} \; \omega_{g,e}>0$, $$\text{ATT}_{e} = \sum_{g:\; w_{g,e}>0} \omega_{g,e} \text{DiD}_{g,e} $$

\vspace{-0.05cm}

\end{frame}


 

\begin{frame}{Estimator used by DiD for Big Data (1/4)}



\textbf{Estimator based on averages.} Replacing population means with sample means, the package  implements the following DiD:

\vspace{-0.55cm}

\begin{equation} \notag  
\textrm{DiD}_{g,e} 
{=}
\underbrace{ \mathbb{E}[Y_{i,g+e} - Y_{i,g+b}  | {\color{blue} G_i {=} g} ] }_{\textbf{Difference for treated group}}
{-} \underbrace{
\left(
  \mathbb{E}[Y_{i,g+e} - Y_{i,g+b} | {\color{red} \mathcal{C}_{g,e}(G_i) {=} 1}]      
\right) 
  }_{\textbf{Difference for control group}}  
\end{equation}
 
\vspace{-0.2cm}

where, following Callaway and Sant'Anna (2021), we require that parallel-trends and no-anticipation holds for one of these 3 possible control groups:
\begin{equation} \notag
\begin{aligned}
\text{``all"} & \quad {\color{red} \mathcal{C}_{g,e}(G_i)} = 
1\{ G_i > (g+e) \} \\
\text{``future-treated"} & \quad {\color{red} \mathcal{C}_{g,e}(G_i)} = 
1\{ G_i > (g+e) \; \& \; G_i < \infty \} \\
\text{``never-treated"} & \quad {\color{red} \mathcal{C}_{g,e}(G_i)} = 
1\{  G_i = \infty \}
\end{aligned}
\end{equation}

\vspace{-0.05cm} 

\textbf{Researcher choices.} The DiD researcher must make 3 choices:
\vspace{-0.1cm}
\begin{itemize}
\item[\textbf{1.}] What is the range of event times $e$  for which you would like $\text{ATT}_e$ estimates? Default: $e=-5,...,5$.
\item[\textbf{2.}] Which pre-period should be the base? Default: $b=-1$.
\item[\textbf{3.}] Which of the 3 control selections ${\color{red} \mathcal{C}}$ to use? Default: ``all".
\end{itemize}


\end{frame}







\begin{frame}{Estimator used by DiD for Big Data (2/4)}

Fix some $(e,b)$. Consider testing $\text{ATT}_{g,e} =0$.

\textbf{Notation:} Consider treatment group ${\color{blue}\mathcal{T}_g} \equiv 1\{G_i =g\}$ and control group ${\color{red}\mathcal{C}_g}$, which could be any of the three options above.  

Define within-$i$ differences ${\color{blue}A_{i}} \equiv Y_{i,g+e} - Y_{i,g+b}, i\in{\color{blue}\mathcal{T}_g}$ with mean ${\color{blue}\mu_{A,g}}\equiv \mathbb{E}[{\color{blue}A}_{i} | i \in {\color{blue}\mathcal{T}_{g}} ]$, and ${\color{red}B_{i}} \equiv Y_{i,g+e} - Y_{i,g+b}, i\in{\color{red}\mathcal{C}_g}$ with mean ${\color{red}\mu_{B,g}} \equiv \mathbb{E}[{\color{red}B_i} |  i\in{\color{red}\mathcal{C}_g}]$, where subscripts are dropped if unambiguous.

\textbf{Hypothesis Testing:}  Since $\text{ATT}_{g,e} \equiv {\color{blue}\mu_{A,g}} - {\color{red}\mu_{B,g}}$, consider,
\vspace{-0.03cm}
\begin{equation} \notag
\text{Test statistic:} \;\; \text{DiD}_{g,e} = {\color{blue}\overline{A}_g} - {\color{red}\overline{B}_g} , \quad \text{Null} \;\; H_0:   {\color{blue}\mu_{A,g}} - {\color{red}\mu_{B,g}} = 0
\end{equation}


\vspace{-0.12cm}

\textbf{Central Limit Theorem:} Denote the population variances by ${\color{blue}\sigma^2_{A,g}}\equiv \text{Var}[{\color{blue}A}_{i} | i \in {\color{blue}\mathcal{T}_g} ]$ and ${\color{red}\sigma^2_{B,g}} \equiv \text{Var}[{\color{red}B_i} |  i\in{\color{red}\mathcal{C}_g}]$. By the CLT under the null, with samples  drawn independently across $i$,  
\vspace{-0.03cm}
\begin{equation} \notag
 {\color{blue}\overline{A}_g} \sim_d \mathcal{N}\left( {\color{blue}\mu_{A,g}} , \; {\color{blue}\sigma^2_{A,g}}/N_{A,g} \right), \quad  {\color{red}\overline{B}_g} \sim_d \mathcal{N}\left( {\color{red}\mu_{B,g}} , \; {\color{red}\sigma^2_{B,g}}/N_{B,g} \right) 
\end{equation}
\begin{equation} \notag
\implies  \text{DiD}_{g,e} = \left(  {\color{blue}\overline{A}_g} - {\color{red}\overline{B}_g} \right) \sim_d  \mathcal{N}\left( 0 , \;  {\color{blue}\sigma^2_{A,g}}/N_{A,g}  + {\color{red}\sigma^2_{B,g}}/N_{B,g}   \right)
\end{equation}
Thus,  $\text{SE}(\text{DiD}_{g,e}) = \sqrt{{\color{blue}\sigma^2_{A,g}}/N_{A,g}  + {\color{red}\sigma^2_{B,g}}/N_{B,g}  }$. The empirical counterpart is trivial to compute (e.g. no matrix inversion needed).

 
\end{frame}









\begin{frame}{Estimator used by DiD for Big Data (3/4)}

\vspace{-0.1cm}

Rather than the ATT for a specific cohort $g$, we often are interested in the event time $e$ ATT averaged across cohorts.

\textbf{Average Effects by Event Time.} Let  $\omega_g \equiv \mathbb{E}[G_i =g | G_i < \infty]$ denote the share of treated units in cohort $g$.  We can define,

\vspace{-0.5cm}

\begin{equation} \notag
\text{DiD}_e  {\equiv}  \sum_{g \in \mathcal{G}} \omega_g \text{DiD}_{g,e} {=}  \sum_{g \in \mathcal{G}} \omega_g \left(  {\color{blue}\overline{A}_g} - {\color{red}\overline{B}_g} \right), 
  \; \text{ATT}_e {\equiv} \sum_{g \in \mathcal{G}}  \omega_{g}  ( {\color{blue}\mu_{A,g}} - {\color{red}\mu_{B,g}} )
\end{equation} 

\vspace{-0.25cm}

\textbf{Recall:} For a given $(g,e)$, the treated and control group are mutually exclusive. Thus, independence across $i$ ensures that $\text{Cov}({\color{blue}\overline{A}_g}, {\color{red}\overline{B}_g})=0$. We used this result on the previous slide to obtain simple SEs with no covariance terms for $\text{DiD}_{g,e} = {\color{blue}\overline{A}_g} - {\color{red}\overline{B}_g} $.

\textbf{Repeated $i$ in the event time average.} Unlike $\text{DiD}_{g,e}$, $\text{DiD}_e$ depends on both ${\color{red}\overline{B}_g}$ and ${\color{red}\overline{B}_{g'}}$ for different cohorts $g,g'$. The same individual $i$ often appears in multiple control groups (e.g. never-treated units can appear in all control groups). Thus, it is typically true that $\text{Cov}({\color{red}\overline{B}_g}, {\color{red}\overline{B}_{g'}}) \neq 0$, so we cannot ignore covariance terms when calculating the SE for $\text{DiD}_e$. Similarly, if $g<g'$, we often have $\text{Cov}({\color{red}\overline{B}_g}, {\color{blue}\overline{A}_{g'}}) \neq 0$, since some members $i$ of the control group at $g$ later enter the treated group $g'$.

\end{frame}







\begin{frame}{Estimator used by DiD for Big Data (4/4)}

 
\textbf{Event study parameters:} For $\mathcal{H} \in \{ \mathcal{T} , \mathcal{C} \}$, one may wish to plot averages across event times:
\begin{equation} \notag
\bar{Y}^\mathcal{H}_{g,e} = \sum_{i \in \mathcal{H}_g}Y_{i,g+e} , \;
\text{SE}(\bar{Y}^\mathcal{H}_{g,e}) = \sqrt{\frac{\sigma^2_{\mathcal{H},g,e}}{|\mathcal{H}_g|}},  \; \sigma^2_{\mathcal{H},g,e} = \text{Var}[Y_{i,g+e} | i \in \mathcal{H}_g]
\end{equation} 
\begin{equation} \notag
\bar{Y}^\mathcal{H}_{e} = \sum_{g \in \mathcal{G}}
\omega_g \bar{Y}^\mathcal{H}_{g,e}
 , \;
\text{SE}(\bar{Y}^\mathcal{H}_{g,e}) = \sqrt{\sum_g \omega_g^2 \text{Var}(\bar{Y}^\mathcal{H}_{g,e})},
\end{equation} 

The package provides these means and SEs by default.

\vspace{0.5cm}

\textbf{Plots:} The package also provides automated plots, both for presenting the event study parameters and for presenting the ATT estimates. These can be plotted by $(g,e)$ or by $e$ (average over $g$).

\end{frame}





\begin{frame}{Accounting for Covariates (1/4)}

\vspace{-0.1cm}

\textbf{Recall: Definition of parallel trends.} 
\vspace{-0.1cm}
\begin{equation} \notag
\begin{aligned}
 \exists b<0 \; \text{s.t.} &\quad \mathbb{E}[Y_{i,g+e}({\color{red} \infty}) - Y_{i,g+b}({\color{red} \infty}) | {\color{red} \mathcal{C}_{g,e}(G_i)  {=} 1}] 
\\ &\quad = \mathbb{E}[Y_{i,g+e}({\color{red} \infty}) - Y_{i,g+b}({\color{red} \infty}) | {\color{blue}G_i = g}], \; \forall e \geq 0
\end{aligned}
\end{equation}

\textbf{Time-invariant Covariate:} Suppose potential outcomes in the case with no-treatment are given by the model,
 $$Y_{i,t}(\infty) = \alpha_i + \mu_t + X_i{\color{ForestGreen}\beta_t} + \epsilon_{i,t}$$

Is the parallel-trends condition violated? Note that,
$$Y_{i,g+e}(\infty) - Y_{i,g+b}(\infty) = (\mu_{g+e} - \mu_{g+b}) + X_i({\color{ForestGreen}\beta_{g+e}} - {\color{ForestGreen}\beta_{g+b}})$$

Plugging this into the expectations above, we see that:
\begin{itemize}
\item[1.] If $\beta_{g+e} = \beta_{g+b}$, then  parallel trends holds, as $X_i$ cancels out in $Y_{i,g+e}({\color{red} \infty}) - Y_{i,g+b}({\color{red} \infty})$.
\vspace{0.05cm}
\item[2.] If ${\color{ForestGreen}\beta_{g+e}} \neq {\color{ForestGreen}\beta_{g+b}}$, then parallel trends holds only if,
\begin{equation} \notag
 \mathbb{E}[ X_i  | {\color{red} \mathcal{C}_{g,e}(G_i)  {=} 1}] 
=
\mathbb{E}[ X_i  | {\color{blue}G_i = g}]  
\end{equation}
\end{itemize}
 
\vspace{-0.1cm}

\end{frame}



\begin{frame}{Accounting for Covariates (2/4)}

\vspace{-0.1cm}

\textbf{Recap:} If $Y_{i,t}(\infty) = \alpha_i + \mu_t + X_i{\color{ForestGreen}\beta_t} + \epsilon_{i,t}$ and ${\color{ForestGreen}\beta_{g+e}} \neq {\color{ForestGreen}\beta_{g+b}}$, then parallel trends holds only if,
\begin{equation} \notag
 \mathbb{E}[ X_i  | {\color{red} \mathcal{C}_{g,e}(G_i)  {=} 1}] 
=
\mathbb{E}[ X_i  | {\color{blue} G_i=g} ]  
\end{equation}

\textbf{``Bin" correction:} If $X_i \in \mathcal{X}$ is discrete, parallel trends holds if we condition on treatment and control groups with the same $X_i$ bin:
$$
 \mathbb{E}[ X_i  | {\color{red} \mathcal{C}_{g,e}(G_i)  {=} 1} \; \& \; X_i=x] 
-
\mathbb{E}[ X_i  | {\color{blue} G_i=g}  \; \& \; X_i=x] 
= x-x =0 
$$
Parallel trends must hold in this model when conditioning on treatment and control groups within the same $X_i=x$ bin.

\vspace{0.1cm}

\textbf{Testing:} Define $\text{DiD}_{g,e}(x)$ as follows:
\vspace{-0.05cm}
\begin{equation} \notag
\mathbb{E}[Y_{i,g+e} - Y_{i,g+b}  | {\color{blue} G_i {=} g}  \; \& \; X_i {=} x ] {-}
 \mathbb{E}[Y_{i,g+e} - Y_{i,g+b} | {\color{red} \mathcal{C}_{g,e}(G_i) {=} 1}  \; \& \; X_i {=} x]
\end{equation}
Then, we can test that  $\text{ATT}_{g,e}$ is zero using,
\vspace{-0.05cm}
\begin{equation} \notag
\text{DiD}_{g,e} =   \sum_\mathcal{X} \omega_g(x) \text{DiD}_{g,e}(x),  
\quad
\omega_g(x) = \mathbb{E}[X_i = x | G_i =g]
\end{equation} 
\vspace{-0.4cm}
\begin{equation} \notag
\text{SE}\left( \text{DiD}_{g,e} \right) =  
\sqrt{
\sum_{x \in \mathcal{X}} (\omega_g(x))^2 \text{SE}(\text{DiD}_{g,e}(x))^2
}
\end{equation} 
\vspace{-0.05cm}
There are no covariances because each $i$ has only one $X_i=x$ bin.

\end{frame}



\begin{frame}{Accounting for Covariates (3/4)}

\vspace{-0.1cm}


\textbf{Time-varying Covariates:} Suppose that it is the covariates $X$ rather than the coefficient $\beta$ that varies over time: 
\begin{equation} \notag
Y_{i,t}(\infty) = \alpha_i + \mu_t + {\color{ForestGreen} X_{i,t} }\beta + \epsilon_{i,t}
\end{equation}

\vspace{-0.1cm}

Is parallel trends violated? Note that,
$$Y_{i,g+e}(\infty) - Y_{i,g+b}(\infty) = (\mu_{g+e} - \mu_{g+b}) + \left({\color{ForestGreen}X_{i,g+e}} - {\color{ForestGreen}X_{i,g+b}}\right)\beta $$

Plugging this into the expectations above, parallel trends requires
\begin{equation} \notag
 \mathbb{E}[ X_{i,g+e} - X_{i,g+b}  | {\color{red} \mathcal{C}_{g,e}(G_i)  {=} 1}] 
=
\mathbb{E}[ X_{i,g+e} - X_{i,g+b}  | {\color{blue}G_i = g}]  
\end{equation} 
Though this will not hold in general, it holds if $X$ is age or time, as  $X_{i,g+e} - X_{i,g+b}=(e-b)$ is the same for  $G_i = g$ and $\mathcal{C}$.

\textbf{Discrete correction for time-varying covariates:} Suppose $X \in \mathcal{X}$ is discrete. Then, the difference  $\tilde{X}_i \equiv X_{i,g+e} - X_{i,g+b}$ is also discrete. We can condition on $\tilde{X}_i=x$ and use the same approach we used for time-invariant covariates above.

\vspace{-0.1cm}


\end{frame}




\begin{frame}{Accounting for Covariates (4/4)}

\vspace{-0.1cm}

\textbf{Recall:} We consider the case in which $X$ varies over time:
\begin{equation} \notag
Y_{i,t}(\infty) = \alpha_i + \mu_t + {\color{ForestGreen} X_{i,t} }\beta + \epsilon_{i,t}
\end{equation}

\vspace{0.1cm}

\textbf{Regression representation:} Let $\mathcal{H}_{g,e}$ denote the union of the treated and control group for a particular $(g,e)$ pair. Then, 
\begin{equation} \notag
\begin{aligned}
(Y_{i,g+e} - Y_{i,g+b}) &= \tilde{\mu} + 1\{G_i=g\}(Y_{i,g+e}(g) - Y_{i,g+e}(\infty)) \\
& + (X_{i,g+e} - X_{i,g+b})\beta + \tilde{\epsilon},\quad \forall i \in \mathcal{H}_{g,e}
\end{aligned}
\end{equation}
which is a regression equation \textit{with no fixed effects} that can be estimated separately for each $g,e$ pair. In particular, the coefficient on $1\{G_i=g\}$ recovers $\mathbb{E}[Y_{i,g+e}(g) - Y_{i,g+e}(\infty) | G_i =g]$.

\vspace{0.3cm}

\textbf{OLS:} Thus, we can apply OLS to regress $Y_{i,g+e} - Y_{i,g+b}$ on $1\{G_i=g\}$ and  $X_{i,g+e} - X_{i,g+b}$, using the standard OLS point estimate and SE for the coefficient on $1\{G_i=g\}$. Note that this OLS formulation accommodates both discrete and continuous $X_{i,t}$. Importantly, no fixed effects have to be estimated, even in the case with continuous time-varying covariates -- the regression just has a few regressors, remaining computationally fast and efficient.

\end{frame}



\end{document}

