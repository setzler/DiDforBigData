[{"path":"https://setzler.github.io/DiDforBigData/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 Bradley Setzler Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Background.html","id":"why-do-we-need-a-staggered-did-package-for-big-data","dir":"Articles","previous_headings":"","what":"1. Why do we need a staggered DiD package for big data?","title":"Background","text":"Recently, noticed pattern seminars conferences: presenters acknowledge use staggered estimator, say infeasible context due large sample size. check, wrote simple panel data simulator staggered treatment roll-heterogeneous treatment effects, simulated large samples, applied popular R packages staggered estimation: didimputation implementing approach Borusyak, Jaravel, Spiess (2022); implementing approach Callaway & Sant’Anna (2021); DIDmultiplegt implementing approach de Chaisemartin & D’Haultfoeuille (2020). found successfully estimate staggered 100,000 unique individuals, took . many applications consider small number unique individuals (e.g. state-level analysis 50 states), designs household-level firm-level using administrative data often involve millions unique individuals.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Background.html","id":"this-package","dir":"Articles","previous_headings":"","what":"2. This package","title":"Background","text":"wrote DiDforBigData address 4 issues arise context large administrative datasets: Speed: less 1 minute, DiDforBigData provide estimation inference staggered millions observations personal laptop. orders magnitude faster available software sample size large. Memory: Administrative data often stored crowded servers limited memory available researchers use. DiDforBigData helps using much less memory software. Dependencies: Administrative servers often outside internet access, making difficult install dependencies. package two dependencies, data.table big data management sandwich robust standard error estimation, already installed R distributions. Optionally, use fixest package speed estimation installed. progress package installed, also provide progress bar know much longer estimation take. Parallelization: Administrative servers often large number available processors, processor may slow, important parallelize. DiDforBigData makes parallelization easy long parallel package installed.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Background.html","id":"demonstration","dir":"Articles","previous_headings":"","what":"3. Demonstration","title":"Background","text":"section compare didimputation, (using default option well bstrap=F option), DIDmultiplegt (option brep=40), DiDforBigData R. draw simulated data 3 times per sample size, apply estimator. Results presented median across 3 draws. Sample Size refers number unique individuals. Since 10 simulated years data, sample balanced across years, number observations 10 times number unique individuals. Replication code available .","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Background.html","id":"point-estimates","dir":"Articles","previous_headings":"3. Demonstration","what":"3.1 Point estimates","title":"Background","text":"verify estimators provide similar point estimates standard errors. , show point estimates 95% confidence intervals (using +/- 1.96*SE) estimate event time +1 (averaging across cohorts). true ATT 4 event time +1. also verify two-way fixed-effects OLS estimation find effect 5.5 event time +1 sample large.  caveat: provides standard errors correspond multiple-hypothesis testing thus tend wider single-hypothesis standard errors provided didimputation DiDforBigData.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Background.html","id":"speed-test","dir":"Articles","previous_headings":"3. Demonstration","what":"3.2 Speed test","title":"Background","text":"Small Samples: run-time required complete estimation using package:  see , 20,000 unique individuals, didimpute DIDmultiplegt become slow. get either approach run successfully 100,000 unique individuals, crash R. contrast, DiDforBigData fast can barely seen plot. Large samples: Given failure didimpute DIDmultiplegt 100,000 observations, now restrict attention DiDforBigData. consider much larger samples:  Even 1 million unique individuals (10 million observations), difficult see DiDforBigData plot, estimation requires half minute, versus nearly 1 hour . Thus, DiDforBigData roughly two orders magnitude faster working sample one million individuals.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Background.html","id":"memory-test","dir":"Articles","previous_headings":"3. Demonstration","what":"3.3 Memory test","title":"Background","text":"Small Samples: memory used complete estimation package:  see DIDmultiplegt uses much memory approaches. approaches use relatively little memory sample sizes. Large Samples:  considering large samples, see DiDforBigData uses less quarter memory used .","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/DiDforBigData.html","id":"installation","dir":"Articles","previous_headings":"","what":"0. Installation","title":"Get Started","text":"install package CRAN: install package Github: use package installed: recommended also make sure optional packages installed:","code":"install.packages(\"DiDforBigData\") devtools::install_github(\"setzler/DiDforBigData\") library(DiDforBigData) library(progress) library(fixest) library(parallel)"},{"path":"https://setzler.github.io/DiDforBigData/articles/DiDforBigData.html","id":"prepare-data","dir":"Articles","previous_headings":"","what":"1. Prepare Data","title":"Get Started","text":"provide simple data simulator follows: real data needs “long” format, .e., need variables individual identifier (e.g. id), time variable (e.g. year), cohort treatment begins (e.g. cohort), outcome variable (e.g. Y). variables required. variables can names prefer. going estimation, need prepare list variable names:","code":"sim = SimDiD(sample_size = 400, seed=123)  # true ATTs in the simulation print(sim$true_ATT) #>      cohort event    ATTge #>  1:    2007     0 1.000000 #>  2:    2007     1 2.000000 #>  3:    2007     2 3.000000 #>  4:    2007     3 4.000000 #>  5:    2007     4 5.000000 #>  6:    2007     5 6.000000 #>  7:    2007     6 7.000000 #>  8:    2010     0 1.500000 #>  9:    2010     1 2.500000 #> 10:    2010     2 3.500000 #> 11:    2010     3 4.500000 #> 12:    2012     0 2.000000 #> 13:    2012     1 3.000000 #> 14: Average     0 1.501672 #> 15: Average     1 2.501672 #> 16: Average     2 3.251256 #> 17: Average     3 4.251256 #> 18: Average     4 5.000000 #> 19: Average     5 6.000000 #> 20: Average     6 7.000000  # simulated data simdata = sim$simdata print(simdata) #>        id year cohort         Y #>    1:   1 2003   2010  8.773933 #>    2:   1 2004   2010  9.846116 #>    3:   1 2005   2010  9.963274 #>    4:   1 2006   2010  9.997385 #>    5:   1 2007   2010 10.060080 #>   ---                           #> 4396: 400 2009   2007  8.035127 #> 4397: 400 2010   2007 14.438798 #> 4398: 400 2011   2007 11.973035 #> 4399: 400 2012   2007 13.033367 #> 4400: 400 2013   2007 13.552533 varnames = list() varnames$time_name = \"year\"  varnames$outcome_name = \"Y\" varnames$cohort_name = \"cohort\" varnames$id_name = \"id\""},{"path":"https://setzler.github.io/DiDforBigData/articles/DiDforBigData.html","id":"estimate-did-for-a-single-cohort","dir":"Articles","previous_headings":"","what":"2. Estimate DiD for a Single Cohort","title":"Get Started","text":"choose event time (+3) cohort treated units (2010), estimate : Comparing estimate true ATT , see estimation performed well. Note used -1 base year default. easy change.","code":"did_2010 = DiDge(inputdata = simdata, varnames = varnames,               cohort_time = 2010, event_postperiod = 3)  print(did_2010) #>    Cohort EventTime BaseEvent CalendarTime    ATTge  ATTge_SE Ncontrol Ntreated #> 1:   2010         3        -1         2013 4.629839 0.1962355      101      100"},{"path":"https://setzler.github.io/DiDforBigData/articles/DiDforBigData.html","id":"estimate-did-for-all-cohorts-and-event-times","dir":"Articles","previous_headings":"","what":"3. Estimate DiD for All Cohorts and Event Times","title":"Get Started","text":"Suppose want estimate ATT event time -3 +5. can follows: output () list. One object list results_average, includes average ATT across cohorts: output () results_cohort, includes combinations event times cohorts. large print , let’s just print results event times 1 2: Note: simulated data ends 2013, event time 2 available treatment cohort 2012. take average across multiple event times, use Esets argument. accepts list, item vector event times average:","code":"did_all = DiD(inputdata = simdata, varnames = varnames, min_event = -3, max_event = 5) print(did_all$results_average) #>    EventTime BaseEvent        ATTe    ATTe_SE Ncontrol Ntreated #> 1:        -3        -1 -0.03472821 0.10802340      603      299 #> 2:        -2        -1 -0.06416254 0.09847063      603      299 #> 3:        -1        -1  0.00000000 0.00000000      603      299 #> 4:         0        -1  1.44852075 0.10387376      603      299 #> 5:         1        -1  2.67299583 0.09964407      603      299 #> 6:         2        -1  3.17946138 0.12477922      402      199 #> 7:         3        -1  4.27349270 0.12596253      302      199 #> 8:         4        -1  4.98423853 0.17470913      201       99 #> 9:         5        -1  5.66743134 0.21029573      101       99 print(did_all$results_cohort[EventTime==1 | EventTime==2]) #>    Cohort EventTime BaseEvent CalendarTime    ATTge  ATTge_SE Ncontrol Ntreated #> 1:   2007         1        -1         2008 2.263430 0.1498733      301       99 #> 2:   2007         2        -1         2009 3.083096 0.1666782      301       99 #> 3:   2010         1        -1         2011 2.474058 0.1733037      201      100 #> 4:   2010         2        -1         2012 3.274863 0.1863323      101      100 #> 5:   2012         1        -1         2013 3.277404 0.2117916      101      100 did_all = DiD(inputdata = simdata, varnames = varnames, min_event = -3, max_event = 5,                Esets = list(c(1,2), c(1,2,3))) print(did_all$results_Esets) #>     Eset ATT_Eset ATT_Eset_SE #> 1:   1,2 2.882843  0.08653256 #> 2: 1,2,3 3.379711  0.08502520"},{"path":[]},{"path":"https://setzler.github.io/DiDforBigData/articles/Examples.html","id":"the-control_group-argument","dir":"Articles","previous_headings":"1. Choosing the Control Group","what":"The control_group argument","title":"Examples","text":"Depending empirical context, parallel-trends assumption may hold one possible control groups: \"never-treated\": control units never observed receiving treatment within sampling time frame. \"future-treated\": control units observed receiving treatment within sampling time frame. \"\": include “never-treated” “future-treated” groups. DiDforBigData makes easy choose among possibilities setting control_group argument function.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Examples.html","id":"example","dir":"Articles","previous_headings":"1. Choosing the Control Group","what":"Example","title":"Examples","text":"start simulating data work : can check true ATT simulated data. particular, let’s focus ATT Cohort 2007: also set variable names list DiDforBigData knows variable outcome, variable treatment cohort, etc.: Now, ready estimate . focus ATT 2007 cohort event times -3,…,5. Initially, control group set, function use default option control_group = \"\": now consider changing estimation use “never-treated” control group: Note sample size control group, Ncontrol, now substantially lower. Finally, consider changing use “future-treated” group: see , future-treated cohorts left event time +5, longer possible provide ATT estimate event time +5 using future-treated control group.","code":"sim = SimDiD(seed=123, sample_size = 1000) simdata = sim$simdata print(simdata) #>          id year cohort         Y #>     1:    1 2003   2012  9.556685 #>     2:    1 2004   2012 10.838554 #>     3:    1 2005   2012 10.639781 #>     4:    1 2006   2012 10.768935 #>     5:    1 2007   2012 10.613825 #>    ---                            #> 10996: 1000 2009   2010  6.640274 #> 10997: 1000 2010   2010 10.571372 #> 10998: 1000 2011   2010 11.282597 #> 10999: 1000 2012   2010 13.403816 #> 11000: 1000 2013   2010 12.542082 print(sim$true_ATT[cohort==2007]) #>    cohort event ATTge #> 1:   2007     0     1 #> 2:   2007     1     2 #> 3:   2007     2     3 #> 4:   2007     3     4 #> 5:   2007     4     5 #> 6:   2007     5     6 #> 7:   2007     6     7 varnames = list() varnames$time_name = \"year\"  varnames$outcome_name = \"Y\" varnames$cohort_name = \"cohort\" varnames$id_name = \"id\" did = DiD(inputdata = simdata, varnames = varnames, min_event = -3, max_event=5)  print(did$results_cohort[Cohort==2007]) #>    Cohort EventTime BaseEvent CalendarTime     ATTge   ATTge_SE Ncontrol #> 1:   2007        -3        -1         2004 0.2212255 0.10491102      751 #> 2:   2007        -2        -1         2005 0.1274586 0.10260112      751 #> 3:   2007        -1        -1         2006 0.0000000 0.00000000      751 #> 4:   2007         0        -1         2007 1.3464834 0.11215961      751 #> 5:   2007         1        -1         2008 2.2323825 0.09443787      751 #> 6:   2007         2        -1         2009 3.3705987 0.10350708      751 #> 7:   2007         3        -1         2010 4.2668717 0.10723955      501 #> 8:   2007         4        -1         2011 5.3241860 0.10738958      501 #> 9:   2007         5        -1         2012 6.1964127 0.13611288      251 #>    Ntreated #> 1:      249 #> 2:      249 #> 3:      249 #> 4:      249 #> 5:      249 #> 6:      249 #> 7:      249 #> 8:      249 #> 9:      249 did = DiD(inputdata = simdata, varnames = varnames,            control_group = \"never-treated\", min_event = -3, max_event=5)  print(did$results_cohort[Cohort==2007]) #>    Cohort EventTime BaseEvent CalendarTime       ATTge  ATTge_SE Ncontrol #> 1:   2007        -3        -1         2004  0.10444344 0.1269592      251 #> 2:   2007        -2        -1         2005 -0.05942059 0.1298412      251 #> 3:   2007        -1        -1         2006  0.00000000 0.0000000      251 #> 4:   2007         0        -1         2007  1.27025637 0.1322487      251 #> 5:   2007         1        -1         2008  2.15386918 0.1171451      251 #> 6:   2007         2        -1         2009  3.35116597 0.1288344      251 #> 7:   2007         3        -1         2010  4.11246994 0.1195819      251 #> 8:   2007         4        -1         2011  5.34013939 0.1225179      251 #> 9:   2007         5        -1         2012  6.19641269 0.1361129      251 #>    Ntreated #> 1:      249 #> 2:      249 #> 3:      249 #> 4:      249 #> 5:      249 #> 6:      249 #> 7:      249 #> 8:      249 #> 9:      249 did = DiD(inputdata = simdata, varnames = varnames,            control_group = \"future-treated\", min_event = -3, max_event=5)  print(did$results_cohort[Cohort==2007]) #>    Cohort EventTime BaseEvent CalendarTime     ATTge  ATTge_SE Ncontrol #> 1:   2007        -3        -1         2004 0.2798501 0.1117079      500 #> 2:   2007        -2        -1         2005 0.2212720 0.1081106      500 #> 3:   2007        -1        -1         2006 0.0000000 0.0000000      500 #> 4:   2007         0        -1         2007 1.3847494 0.1183855      500 #> 5:   2007         1        -1         2008 2.2717963 0.1022833      500 #> 6:   2007         2        -1         2009 3.3803539 0.1094793      500 #> 7:   2007         3        -1         2010 4.4218911 0.1294090      250 #> 8:   2007         4        -1         2011 5.3081689 0.1292680      250 #>    Ntreated #> 1:      249 #> 2:      249 #> 3:      249 #> 4:      249 #> 5:      249 #> 6:      249 #> 7:      249 #> 8:      249"},{"path":[]},{"path":"https://setzler.github.io/DiDforBigData/articles/Examples.html","id":"the-base_event-argument","dir":"Articles","previous_headings":"2. Avoiding anticipation","what":"The base_event argument","title":"Examples","text":"designs, researcher must choose base pre-period differences measured. natural choice base_event = -1, means use time period just treatment onset event time 0. discussed Callaway & Sant’Anna (2021), one possibility treatment group begins responding treatment prior treatment onset, called “anticipation.” anticipation begins period -1, differences measured relative base_event = -1 yield inconsistent estimates. Fortunately, easy solution: choose base pre-period anticipation began. seems reasonable assume treatment group anticipated treatment 3 years treatment onset, base_event = -3 free anticipation.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Examples.html","id":"example-1","dir":"Articles","previous_headings":"2. Avoiding anticipation","what":"Example","title":"Examples","text":"can simulate data subject anticipation using anticipation argument SimDiD function: Let’s focus average ATT across cohorts. two periods treatment effects prior treatment, can verify checking true ATT simulation: set varnames prepare estimation: estimate using default argument base_event = -1, estimate biased inconsistent: now set base_event = -3 avoid anticipation -1 -2: see estimate now close true ATT.","code":"sim = SimDiD(seed=123, sample_size = 200, anticipation = 2) simdata = sim$simdata print(simdata) #>        id year cohort         Y #>    1:   1 2003    Inf 11.238356 #>    2:   1 2004    Inf 11.520443 #>    3:   1 2005    Inf 13.252991 #>    4:   1 2006    Inf 11.940777 #>    5:   1 2007    Inf 13.120440 #>   ---                           #> 2196: 200 2009    Inf 10.250944 #> 2197: 200 2010    Inf  8.812227 #> 2198: 200 2011    Inf  9.926592 #> 2199: 200 2012    Inf 11.188476 #> 2200: 200 2013    Inf  9.270495 print(sim$true_ATT[cohort==\"Average\"]) #>     cohort event    ATTge #> 1: Average    -2 0.500000 #> 2: Average    -1 0.500000 #> 3: Average     0 1.503356 #> 4: Average     1 2.503356 #> 5: Average     2 3.252525 #> 6: Average     3 4.252525 #> 7: Average     4 5.000000 #> 8: Average     5 6.000000 #> 9: Average     6 7.000000 varnames = list() varnames$time_name = \"year\"  varnames$outcome_name = \"Y\" varnames$cohort_name = \"cohort\" varnames$id_name = \"id\" did = DiD(inputdata = simdata, varnames = varnames, min_event = -3, max_event=3)  print(did$results_average) #>    EventTime BaseEvent        ATTe   ATTe_SE Ncontrol Ntreated #> 1:        -3        -1 -0.52346600 0.1534229      303      149 #> 2:        -2        -1 -0.04556457 0.1380282      303      149 #> 3:        -1        -1  0.00000000 0.0000000      303      149 #> 4:         0        -1  0.75946293 0.1495045      303      149 #> 5:         1        -1  1.80044696 0.1392958      303      149 #> 6:         2        -1  2.50749407 0.1718781      202       99 #> 7:         3        -1  3.33212214 0.1917002      152       99 did = DiD(inputdata = simdata, varnames = varnames,            base_event = -3, min_event = -3, max_event=3)  print(did$results_average)  #>    EventTime BaseEvent      ATTe   ATTe_SE Ncontrol Ntreated #> 1:        -3        -3 0.0000000 0.0000000      303      149 #> 2:        -2        -3 0.4779014 0.1521152      303      149 #> 3:        -1        -3 0.5234660 0.1534229      303      149 #> 4:         0        -3 1.2829289 0.1441747      303      149 #> 5:         1        -3 2.3239130 0.1485972      303      149 #> 6:         2        -3 2.9653357 0.1643872      202       99 #> 7:         3        -3 3.8282455 0.1773802      152       99"},{"path":[]},{"path":"https://setzler.github.io/DiDforBigData/articles/Examples.html","id":"the-covariate_names-entry","dir":"Articles","previous_headings":"3. Controlling for Time-varying Covariates","what":"The covariate_names entry","title":"Examples","text":"sometimes worry treatment cohorts selected time-varying observables, time-varying observables also directly affect outcome. growth rate observables differs treatment control groups, creates violation parallel-trends assumption: treatment control groups experienced different growth profiles absence treatment due different observables. Fortunately, easy fix: Since confounding variables observable, just need control observables. DiDforBigData requires list variable names, varnames, modified include covariate_names entry. example, varnames$covariate_names = c(\"X1\",\"X2\") tells control linearly time-variation X1 X2.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Examples.html","id":"example-2","dir":"Articles","previous_headings":"3. Controlling for Time-varying Covariates","what":"Example","title":"Examples","text":"option SimDiD() add couple covariates. two covariates, X1 X2. particular, X2 differs growth rates across treatment cohorts, means causes violations parallel trends controlled. set varnames prepare estimation, ignoring covariates now: verify gives wrong answer cohort 2007: control linearly X1 X2, just need add covariate_names argument varnames: Now check controls time-variation X1 X2: see bias removed thanks control variables.","code":"sim = SimDiD(sample_size=1000, time_covars=TRUE) simdata = sim$simdata print(simdata) #>          id year cohort         Y          X1           X2 #>     1:    1 2003   2007 11.763806 -5.28713552 -0.546247081 #>     2:    1 2004   2007 14.216536 -3.16836592  0.882383754 #>     3:    1 2005   2007 12.898204 -3.52698674 -0.007446627 #>     4:    1 2006   2007 14.117949 -3.83264390 -0.307454720 #>     5:    1 2007   2007  9.932859  0.04643156  0.153863150 #>    ---                                                     #> 10996: 1000 2009   2010 10.096541 -0.96662668 -0.375274801 #> 10997: 1000 2010   2010  6.679059  4.38379275  0.229111354 #> 10998: 1000 2011   2010  8.328832  4.11630763  0.242690466 #> 10999: 1000 2012   2010  9.171007  3.05442888  2.269272560 #> 11000: 1000 2013   2010  9.044345  4.46350435  0.510888022  print(sim$true_ATT[cohort==2007]) #>    cohort event ATTge #> 1:   2007     0     1 #> 2:   2007     1     2 #> 3:   2007     2     3 #> 4:   2007     3     4 #> 5:   2007     4     5 #> 6:   2007     5     6 #> 7:   2007     6     7 varnames = list() varnames$time_name = \"year\"  varnames$outcome_name = \"Y\" varnames$cohort_name = \"cohort\" varnames$id_name = \"id\" did = DiD(inputdata = simdata, varnames = varnames, min_event = -3, max_event=5)  print(did$results_cohort[Cohort==2007]) #>    Cohort EventTime BaseEvent CalendarTime     ATTge  ATTge_SE Ncontrol #> 1:   2007        -3        -1         2004 0.1677000 0.1877317      751 #> 2:   2007        -2        -1         2005 0.2901911 0.1778623      751 #> 3:   2007        -1        -1         2006 0.0000000 0.0000000      751 #> 4:   2007         0        -1         2007 1.1509604 0.1816170      751 #> 5:   2007         1        -1         2008 2.8765749 0.1862649      751 #> 6:   2007         2        -1         2009 4.3001933 0.1904476      751 #> 7:   2007         3        -1         2010 5.4489463 0.2012098      501 #> 8:   2007         4        -1         2011 6.8211665 0.1907504      501 #> 9:   2007         5        -1         2012 7.9496252 0.2256687      251 #>    Ntreated #> 1:      249 #> 2:      249 #> 3:      249 #> 4:      249 #> 5:      249 #> 6:      249 #> 7:      249 #> 8:      249 #> 9:      249 varnames$covariate_names = c(\"X1\",\"X2\") did = DiD(inputdata = simdata, varnames = varnames, min_event = -3, max_event=5)  print(did$results_cohort[Cohort==2007]) #>    Cohort EventTime BaseEvent CalendarTime      ATTge  ATTge_SE Ncontrol #> 1:   2007        -3        -1         2004 -0.1225027 0.1074379      751 #> 2:   2007        -2        -1         2005  0.1021934 0.1042450      751 #> 3:   2007        -1        -1         2006  0.0000000 0.0000000      751 #> 4:   2007         0        -1         2007  0.9427569 0.1066192      751 #> 5:   2007         1        -1         2008  2.0692206 0.1117700      751 #> 6:   2007         2        -1         2009  2.8921399 0.1144014      751 #> 7:   2007         3        -1         2010  3.9086404 0.1233646      501 #> 8:   2007         4        -1         2011  5.1380269 0.1275067      501 #> 9:   2007         5        -1         2012  5.9657885 0.1503580      251 #>    Ntreated #> 1:      249 #> 2:      249 #> 3:      249 #> 4:      249 #> 5:      249 #> 6:      249 #> 7:      249 #> 8:      249 #> 9:      249"},{"path":[]},{"path":"https://setzler.github.io/DiDforBigData/articles/Examples.html","id":"the-cluster_names-entry","dir":"Articles","previous_headings":"4. Robust and Clustered Standard Errors","what":"The cluster_names entry","title":"Examples","text":"default, package always provides heteroskedasticity-robust standard errors. However, difference--differences applications, often case treatment assigned groups individuals (e.g., change state-wide policy treats individuals state simultaneously). groups also subject common shocks, induces correlation estimation errors within cluster, standard errors tend small. Fortunately, easy fix: groups within estimation errors correlated known researcher, just need cluster standard errors group. DiDforBigData requires list variable names, varnames, modified include cluster_names entry. example, varnames$cluster_names = c(\"group1\",\"group2\") tells use multi-way clustering way accounts common shocks observable groups, “group1” “group2”. Note: estimating regression combines multiple treatment cohorts /multiple event times, necessary always cluster unit (individual). DiDforBigData adds clustering default.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Examples.html","id":"example-3","dir":"Articles","previous_headings":"4. Robust and Clustered Standard Errors","what":"Example","title":"Examples","text":"option SimDiD() using clusters=TRUE group individuals bins differentially selected treatment also face common shocks within bin: set varnames prepare estimation: check usual standard errors, clustered unit based varnames$id_name default: Next, cluster “cluster” variable adding varnames re-estimating:","code":"sim = SimDiD(sample_size=1000, clusters = TRUE) simdata = sim$simdata print(simdata) #>          id year cohort         Y cluster #>     1:    1 2003   2007  8.266417       9 #>     2:    1 2004   2007 12.657646       9 #>     3:    1 2005   2007  9.373441       9 #>     4:    1 2006   2007 10.851528       9 #>     5:    1 2007   2007  9.306055       9 #>    ---                                    #> 10996: 1000 2009   2010 10.317600       6 #> 10997: 1000 2010   2010  9.623423       6 #> 10998: 1000 2011   2010 11.509660       6 #> 10999: 1000 2012   2010  9.718423       6 #> 11000: 1000 2013   2010 11.042858       6  print(sim$true_ATT[cohort==\"Average\"]) #>     cohort event    ATTge #> 1: Average     0 1.500668 #> 2: Average     1 2.500668 #> 3: Average     2 3.250501 #> 4: Average     3 4.250501 #> 5: Average     4 5.000000 #> 6: Average     5 6.000000 #> 7: Average     6 7.000000 varnames = list() varnames$time_name = \"year\"  varnames$outcome_name = \"Y\" varnames$cohort_name = \"cohort\" varnames$id_name = \"id\" did = DiD(inputdata = simdata, varnames = varnames, min_event = -1, max_event=3)  print(did$results_average) #>    EventTime BaseEvent     ATTe    ATTe_SE Ncontrol Ntreated #> 1:        -1        -1 0.000000 0.00000000     1503      749 #> 2:         0        -1 1.654672 0.07813674     1503      749 #> 3:         1        -1 2.710981 0.09333436     1503      749 #> 4:         2        -1 3.319803 0.11998209     1002      499 #> 5:         3        -1 4.597428 0.12376782      752      499 varnames$cluster_names = \"cluster\"   did = DiD(inputdata = copy(simdata), varnames = varnames, min_event = -1, max_event=3)  print(did$results_average) #>    EventTime BaseEvent     ATTe    ATTe_SE Ncontrol Ntreated #> 1:        -1        -1 0.000000 0.00000000     1503      749 #> 2:         0        -1 1.654672 0.08714482     1503      749 #> 3:         1        -1 2.710981 0.11885828     1503      749 #> 4:         2        -1 3.319803 0.13355642     1002      499 #> 5:         3        -1 4.597428 0.25745379      752      499"},{"path":[]},{"path":"https://setzler.github.io/DiDforBigData/articles/Examples.html","id":"the-parallel_cores-argument","dir":"Articles","previous_headings":"5. Parallelization","what":"The parallel_cores argument","title":"Examples","text":"parallel package installed, trivial execute estimation parallel setting parallel_cores argument () command. example, (..., parallel_cores = 4) utilize 4 cores parallel. determine many cores available system, just run command parallel::detectCores() R. (suggest leaving least 1 core free keep system freezing.) parallel processing usually interact well progress bar, written modified version R’s parallelization protocol correctly updates progress bar completes tasks. Thus, progress package installed, correctly see progress bar predicted completion time estimation executing parallel.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Examples.html","id":"example-4","dir":"Articles","previous_headings":"5. Parallelization","what":"Example","title":"Examples","text":"simulate data: set varnames prepare estimation: run estimation parallel: run estimation parallel 2 processes:","code":"sim = SimDiD(seed=123, sample_size = 1000) simdata = sim$simdata varnames = list() varnames$time_name = \"year\"  varnames$outcome_name = \"Y\" varnames$cohort_name = \"cohort\" varnames$id_name = \"id\" did = DiD(inputdata = copy(simdata), varnames = varnames, min_event = -1, max_event=3) did = DiD(inputdata = copy(simdata), varnames = varnames, min_event = -1, max_event=3, parallel_cores = 2)"},{"path":[]},{"path":"https://setzler.github.io/DiDforBigData/articles/Examples.html","id":"the-esets-argument","dir":"Articles","previous_headings":"6. Average across Event Times","what":"The Esets argument","title":"Examples","text":"Suppose wish average estimate across event times, corresponding standard error average across event times. done providing list Esets argument () command. example, Esets = list(c(1,2,3)), output include average event times e=1,2,3. Multiple sets event times can provided, e.g., Esets = list(c(1,2,3), c(1,3)) provide average across e=1,2,3 well average e=1 e=3. Event set averages returned $results_Esets argument output list. Sample size provided, unclear define sample size averaging multiple statistics, different sample size.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Examples.html","id":"example-5","dir":"Articles","previous_headings":"6. Average across Event Times","what":"Example","title":"Examples","text":"simulate data: set varnames prepare estimation: run estimation two event set averages:","code":"sim = SimDiD(seed=123, sample_size = 1000) simdata = sim$simdata varnames = list() varnames$time_name = \"year\"  varnames$outcome_name = \"Y\" varnames$cohort_name = \"cohort\" varnames$id_name = \"id\" did = DiD(inputdata = copy(simdata), varnames = varnames, min_event = -1, max_event=3, Esets = list(c(1,2,3), c(1,3)))  print(did) #> $results_cohort #>     Cohort EventTime BaseEvent CalendarTime    ATTge   ATTge_SE Ncontrol #>  1:   2007        -1        -1         2006 0.000000 0.00000000      751 #>  2:   2007         0        -1         2007 1.346483 0.11215961      751 #>  3:   2007         1        -1         2008 2.232383 0.09443787      751 #>  4:   2007         2        -1         2009 3.370599 0.10350708      751 #>  5:   2007         3        -1         2010 4.266872 0.10723955      501 #>  6:   2010        -1        -1         2009 0.000000 0.00000000      501 #>  7:   2010         0        -1         2010 1.506723 0.10838000      501 #>  8:   2010         1        -1         2011 2.660030 0.10325447      501 #>  9:   2010         2        -1         2012 3.637140 0.12739621      251 #> 10:   2010         3        -1         2013 4.398071 0.12737026      251 #> 11:   2012        -1        -1         2011 0.000000 0.00000000      251 #> 12:   2012         0        -1         2012 1.920898 0.13066712      251 #> 13:   2012         1        -1         2013 2.786013 0.12683651      251 #>     Ntreated #>  1:      249 #>  2:      249 #>  3:      249 #>  4:      249 #>  5:      249 #>  6:      250 #>  7:      250 #>  8:      250 #>  9:      250 #> 10:      250 #> 11:      250 #> 12:      250 #> 13:      250 #>  #> $results_average #>    EventTime BaseEvent     ATTe    ATTe_SE Ncontrol Ntreated #> 1:        -1        -1 0.000000 0.00000000     1503      749 #> 2:         0        -1 1.591695 0.06629046     1503      749 #> 3:         1        -1 2.559912 0.06200891     1503      749 #> 4:         2        -1 3.504136 0.08179983     1002      499 #> 5:         3        -1 4.332603 0.08219426      752      499 #>  #> $results_Esets #>     Eset ATT_Eset ATT_Eset_SE #> 1: 1,2,3 3.340838  0.05596817 #> 2:   1,3 3.251005  0.05801106"},{"path":[]},{"path":"https://setzler.github.io/DiDforBigData/articles/Theory.html","id":"notation-and-key-concepts","dir":"Articles","previous_headings":"1. Conceptual Framework","what":"1.1 Notation and Key Concepts","title":"Theory","text":"\\(\\): Index individual unit. \\(t\\): Time period. \\(D_{,t}\\): Binary indicator treatment. assume throughout treatment received permanently received first time. words, \\(D_{,t}=1 \\implies D_{,t+1}=1\\). \\(G_i\\): Treatment cohort, .e., time treatment first received \\(\\). , \\(G_i = g \\implies D_{,t}=1, \\forall t\\geq g\\). Note: treatment received, \\(G_i = \\infty\\). \\(Y_{,t}\\): Observed outcome interest. \\(Y_{,t}(g)\\): Counterfactual outcome treatment cohort \\(G_i=g\\).","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Theory.html","id":"goal","dir":"Articles","previous_headings":"1. Conceptual Framework","what":"1.2 Goal","title":"Theory","text":"goal identify average treatment effect treated (ATT), cohort \\(g\\) event time \\(e \\equiv t-g\\), defined : \\[ \\text{ATT}_{g,e} \\equiv \\mathbb{E}[Y_{,g+e}(g) - Y_{,g+e}(\\infty) | G_i = g] \\] may also interested average ATT across treated cohorts given event time: \\[ \\text{ATT}_{e} \\equiv \\sum_g \\omega_{g,e} \\text{ATT}_{g,e}, \\quad \\omega_{g,e} \\equiv \\frac{\\sum_i 1\\{G_i=g\\}}{\\sum_i 1\\{G_i < \\infty\\}} \\] Lastly, may interested average across certain event times average ATT across cohorts: \\[ \\text{ATT}_{E} \\equiv \\frac{1}{|E|} \\sum_{e \\E} \\text{ATT}_{e} \\] \\(E\\) set event times, e.g., \\(E = \\{1,2,3\\}\\).","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Theory.html","id":"difference-in-differences","dir":"Articles","previous_headings":"1. Conceptual Framework","what":"1.3 Difference-in-differences","title":"Theory","text":"Control group: treated cohort \\(G_i = g\\), let \\(C_{g,e}\\) denote corresponding set units \\(\\) belong control group. minimum, control group must satisfy \\(\\C_{g,e} \\implies G_i > \\max\\{g, g+e\\}\\). says control group must belong later cohort treated group interest, control group must treated yet event time interest. Base event time: consider reference event time treatment \\(b\\), satisfies \\(b<0\\). Difference--differences: difference--differences estimand defined , \\[ \\text{}_{g,e} \\equiv \\mathbb{E}[Y_{,g+e} - Y_{,g+b} | G_i = g] -  \\mathbb{E}[Y_{,g+e} - Y_{,g+b}  | \\C_{g,e}] \\]","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Theory.html","id":"identification","dir":"Articles","previous_headings":"","what":"2. Identification","title":"Theory","text":"Throughout section, goal identify \\(\\text{ATT}_{g,e}\\) treated cohort \\(g\\) event time \\(e\\). take base event time \\(b<0\\) given.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Theory.html","id":"identifying-assumptions","dir":"Articles","previous_headings":"2. Identification","what":"2.1 Identifying Assumptions","title":"Theory","text":"Parallel Trends: \\[ \\mathbb{E}[Y_{,g+e}(\\infty) - Y_{,g+b}(\\infty) | G_i = g] = \\mathbb{E}[Y_{,g+e}(\\infty) - Y_{,g+b}(\\infty) | \\C_{g,e}] \\] says , absence treatment, treatment control groups experienced average change outcomes event time \\(b\\) event time \\(e\\). Anticipation: \\[ \\mathbb{E}[  Y_{,g+b}(g) | G_i = g] = \\mathbb{E}[ Y_{,g+b}(\\infty) | G_i = g] \\] says , base event time \\(b\\), observed outcome treated cohort instead assigned never receive treatment.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Theory.html","id":"proof-of-identification-by-did","dir":"Articles","previous_headings":"2. Identification","what":"2.2 Proof of Identification by DiD","title":"Theory","text":"prove \\(\\text{}_{g,e}\\) identifies \\(\\text{ATT}_{g,e}\\) three steps: Step 1: Add subtract \\(Y_{,g+b}(\\infty)\\) ATT definition: \\[ \\text{ATT}_{g,e} \\equiv \\mathbb{E}[Y_{,g+e}(g) - Y_{,g+e}(\\infty) | G_i = g] \\] \\[ = \\mathbb{E}[Y_{,g+e}(g) - Y_{,g+b}(\\infty) | G_i = g] - \\mathbb{E}[Y_{,g+e}(\\infty) - Y_{,g+b}(\\infty) | G_i = g] \\] Step 2: Assume Parallel Trends holds. , can replace conditioning set \\(G_i=g\\) conditioning set \\(\\C_{g,e}\\) second term: \\[ \\text{ATT}_{g,e} = \\mathbb{E}[Y_{,g+e}(g) - Y_{,g+b}(\\infty) | G_i = g] - \\mathbb{E}[Y_{,g+e}(\\infty) - Y_{,g+b}(\\infty) | G_i = g] \\] \\[ = \\mathbb{E}[Y_{,g+e}(g) - Y_{,g+b}(\\infty) | G_i = g] - \\mathbb{E}[Y_{,g+e}(\\infty) - Y_{,g+b}(\\infty) | \\C_{g,e}] \\] Step 3: Assume Anticipation holds. , can replace \\(Y_{,g+b}(\\infty)\\) \\(Y_{,g+b}(g)\\) conditioning set \\(G_i = g\\): \\[ \\text{ATT}_{g,e} = \\mathbb{E}[Y_{,g+e}(g) - Y_{,g+b}(\\infty) | G_i = g] - \\mathbb{E}[Y_{,g+e}(\\infty) - Y_{,g+b}(\\infty) | \\C_{g,e}] \\] \\[ = \\mathbb{E}[Y_{,g+e}(g) - Y_{,g+b}(g) | G_i = g] - \\mathbb{E}[Y_{,g+e}(\\infty) - Y_{,g+b}(\\infty) | \\C_{g,e}] \\] final expression \\(\\text{}_{g,e}\\). Thus, shown \\(\\text{}_{g,e} = \\text{ATT}_{g,e}\\) Parallel Trends Anticipation hold.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Theory.html","id":"the-didge----command","dir":"Articles","previous_headings":"","what":"3. The DiDge(...) Command","title":"Theory","text":"\\(\\text{}_{g,e}\\) estimated DiDforBigData DiDge(...) command, documented .","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Theory.html","id":"automatic-control-group-selection","dir":"Articles","previous_headings":"3. The DiDge(...) Command","what":"3.1 Automatic Control Group Selection","title":"Theory","text":": largest valid control group \\(C_{g,e} \\equiv \\{ : G_i > \\max\\{g, g+e\\}\\}\\). use control group, specify control_group = \"\" DiDge(...) command. option selected default. Two alternatives can specified. Never-treated: never-treated control group defined \\(C_{g,e} \\equiv \\{ : G_i = \\infty \\}\\). use control group, specify control_group = \"never-treated\" DiDge(...) command. Future-treated: future-treated control group defined \\(C_{g,e} \\equiv \\{ : G_i > \\max\\{g, g+e\\} \\text{ } G_i < \\infty\\}\\). use control group, specify control_group = \"future-treated\" DiDge(...) command. Base event time: base event time can specified using base_event argument DiDge(...), base_event = -1 default.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Theory.html","id":"did-estimation-for-a-single-ge-combination","dir":"Articles","previous_headings":"3. The DiDge(...) Command","what":"3.2 DiD Estimation for a Single \\((g,e)\\) Combination","title":"Theory","text":"DiDge() command performs following sequence steps: Step 1. Define \\((g,e)\\)-specific sample treated control units, \\(S_{g,e} \\equiv \\{G_i=g\\} \\cup \\{\\C_{g,e}\\}\\). Drop observations satisfy \\(\\S_{g,e}\\). Step 2. Construct within-\\(\\) differences \\(\\Delta Y_{,g+e} \\equiv Y_{,g+e} - Y_{,g+b}\\) \\(\\S_{g,e}\\). Step 3. Estimate simple linear regression \\(\\Delta Y_{,g+e} = \\alpha_{g,e} + \\beta_{g,e} 1\\{G_i =g\\} + \\epsilon_{,g+e}\\) OLS \\(\\S_{g,e}\\). OLS estimate \\(\\beta_{g,e}\\) equivalent \\(\\text{}_{g,e}\\). standard error provided OLS \\(\\beta_{g,e}\\) equivalent standard error two-sample test equal means null hypothesis \\[\\mathbb{E}[\\Delta Y_{,g+e} | G_i = g] =  \\mathbb{E}[\\Delta Y_{,g+e} | \\C_{g,e}] \\] equivalent testing \\(\\text{ATT}_{g,e}=0\\).","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Theory.html","id":"the-did----command","dir":"Articles","previous_headings":"","what":"4. The DiD(...) Command","title":"Theory","text":"DiDforBigData uses (...) command estimate \\(\\text{}_{g,e}\\) available cohorts \\(g\\) across range possible event times \\(e\\); (...) documented .","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Theory.html","id":"did-estimation-for-all-possible-ge-combinations","dir":"Articles","previous_headings":"4. The DiD(...) Command","what":"4.1 DiD Estimation for All Possible \\((g,e)\\) Combinations","title":"Theory","text":"(...) uses control_group base_event arguments way DiDge(...). (...) also uses min_event max_event arguments choose minimum maximum event times \\(e\\) interest. arguments specified, assumes possible event times interest. practice, (...) completes following steps: Step 1. Determine possible combinations \\((g,e)\\) available data. min_event max_event arguments allow user restrict minimum maximum event times \\(e\\) interest. Step 2. parallel, \\((g,e)\\) combination, construct corresponding control group \\(C_{g,e}\\) way DiDge(...). Drop \\((g,e)\\) combination control group empty. Step 3. Within \\((g,e)\\)-specific process, define \\((g,e)\\)-specific sample treated control units, \\(S_{g,e} \\equiv \\{G_i=g\\} \\cup \\{\\C_{g,e}\\}\\). Drop observations satisfy \\(\\S_{g,e}\\). Step 4. Within \\((g,e)\\)-specific process, construct within-\\(\\) differences \\(\\Delta Y_{,g+e} \\equiv Y_{,g+e} - Y_{,g+b}\\) \\(\\) remains sample. Step 5. Within \\((g,e)\\)-specific process, estimate \\(\\Delta Y_{,g+e} = \\alpha_{g,e} + \\beta_{g,e} 1\\{G_i =g\\} + \\epsilon_{,g+e}\\) OLS. OLS estimate \\(\\beta_{g,e}\\) equivalent \\(\\text{}_{g,e}\\). standard error provided OLS \\(\\beta_{g,e}\\) equivalent standard error two-sample test equal means null hypothesis \\[\\mathbb{E}[\\Delta Y_{,g+e} | G_i = g] =  \\mathbb{E}[\\Delta Y_{,g+e} | \\C_{g,e}] \\] equivalent testing \\(\\text{ATT}_{g,e}=0\\). Note \\(\\text{ATT}_{g,e}=0\\) tested single hypothesis \\((g,e)\\) combination; adjustment multiple hypothesis testing applied.","code":""},{"path":"https://setzler.github.io/DiDforBigData/articles/Theory.html","id":"estimate-the-average-att-across-cohorts-and-event-times","dir":"Articles","previous_headings":"4. The DiD(...) Command","what":"4.2 Estimate the Average ATT across Cohorts and Event Times","title":"Theory","text":"Aside estimating \\(\\text{ATT}_{g,e}\\), (...) also estimates \\(\\text{ATT}_{e}\\) \\(e\\) included event times interest. , (...) completes following steps: Step 1. end \\((g,e)\\)-specific estimation parallel described , returns various \\((g,e)\\)-specific samples form \\(S_{g,e} \\equiv \\{G_i=g\\} \\cup \\{\\C_{g,e}\\}\\). Step 2. defines indicator corresponding cohort \\(g\\), stacks samples \\(S_{g,e}\\) \\(e\\). Note \\(\\) can appear multiple times due membership \\(S_{g_1,e}\\) \\(S_{g_2,e}\\), distinct observations distinguished indicators \\(g\\). Step 3. estimates \\(\\Delta Y_{,g+e} = \\sum_g \\alpha_{g,e} + \\sum_g \\beta_{g,e} 1\\{G_i =g\\} + \\epsilon_{,g+e}\\) OLS stacked sample across \\(g\\). Step 4. constructs \\(\\text{}_e = \\sum_g \\omega_{g,e} \\beta_{g,e}\\), \\(\\omega_{g,e} \\equiv \\frac{\\sum_i 1\\{G_i=g\\}}{\\sum_i 1\\{G_i < \\infty\\}}\\). Since \\(\\beta_{g,e}\\) estimate corresponding \\(\\text{ATT}_{g,e}\\), follows \\(\\text{}_e\\) estimate weighted average \\(\\text{ATT}_{e} \\equiv \\sum_g \\omega_{g,e} \\text{ATT}_{g,e}\\). Step 5. test null hypothesis \\(\\text{ATT}_{e} = 0\\), defines \\(\\bar\\beta_e = (\\beta_{g,e})_g\\) \\(\\bar\\omega_e = (\\omega_{g,e})_g\\). Note \\(\\text{}_e = \\bar\\omega_e' \\bar\\beta_e\\). get standard error, \\(\\text{}_e\\), uses \\(\\text{Var}(\\text{}_e) = \\bar\\omega_e' \\text{Var}(\\bar\\beta_e) \\bar\\omega_e\\), \\(\\text{Var}(\\bar\\beta_e)\\) usual (heteroskedasticity-robust) variance-covariance matrix OLS coefficients. Since unit \\(\\) appears multiple rows sample, must cluster \\(\\) estimating \\(\\text{Var}(\\bar\\beta_e)\\). Finally, standard error corresponding null hypothesis \\(\\text{ATT}_{e} = 0\\) \\(\\sqrt{\\text{Var}(\\text{}_e)}\\). similar approach used estimate \\(\\text{ATT}_{E}\\) across set event times \\(E\\), using can represented linear combination OLS coefficients \\(\\beta_{g,e}\\) appropriate weights.","code":""},{"path":"https://setzler.github.io/DiDforBigData/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Bradley Setzler. Author, maintainer, copyright holder.","code":""},{"path":"https://setzler.github.io/DiDforBigData/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Setzler B (2023). DiDforBigData: Big Data Implementation Difference--Differences Estimation Staggered Treatment. R package version 1.0.0.9000, https://setzler.github.io/DiDforBigData/.","code":"@Manual{,   title = {DiDforBigData: A Big Data Implementation of Difference-in-Differences Estimation with Staggered Treatment},   author = {Bradley Setzler},   year = {2023},   note = {R package version 1.0.0.9000},   url = {https://setzler.github.io/DiDforBigData/}, }"},{"path":"https://setzler.github.io/DiDforBigData/index.html","id":"did-for-big-data-in-r","dir":"","previous_headings":"","what":"A Big Data Implementation of Difference-in-Differences Estimation with Staggered Treatment","title":"A Big Data Implementation of Difference-in-Differences Estimation with Staggered Treatment","text":"R package provides big-data-friendly memory-efficient difference--differences () estimator staggered (non-staggered) treatment contexts. supports controlling time-varying covariates, heteroskedasticity-robust standard errors, (single multi-way) clustered standard errors. addresses 4 issues arise context large administrative datasets: Speed: less 1 minute, DiDforBigData provide estimation inference staggered millions observations personal laptop. orders magnitude faster available software sample size large; see demonstration . Memory: Administrative data often stored crowded servers limited memory available researchers use. DiDforBigData helps using much less memory software; see demonstration . Dependencies: Administrative servers often outside internet access, making difficult install dependencies. package two dependencies, data.table big data management sandwich robust standard error estimation, already installed R distributions. Optionally, use fixest package speed estimation installed. progress package installed, also provide progress bar know much longer estimation take. Parallelization: Administrative servers often large number available processors, processor may slow, important parallelize. DiDforBigData makes parallelization easy long parallel package installed.","code":""},{"path":"https://setzler.github.io/DiDforBigData/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Big Data Implementation of Difference-in-Differences Estimation with Staggered Treatment","text":"install package CRAN: install package Github: use package installed: recommended also make sure optional packages installed:","code":"install.packages(\"DiDforBigData\") devtools::install_github(\"setzler/DiDforBigData\") library(DiDforBigData) library(progress) library(fixest) library(parallel)"},{"path":"https://setzler.github.io/DiDforBigData/index.html","id":"basic-usage","dir":"","previous_headings":"","what":"Basic Usage","title":"A Big Data Implementation of Difference-in-Differences Estimation with Staggered Treatment","text":"3 functions package: DiDge(): function estimates single cohort single event time. (): function estimates available cohorts event times. SimDiD(): function simulates data. Details function available Function Documentation. estimation, set variable list names variables: estimate single cohort event time, use DiDge command. example: detailed manual explaining various features available DiDge available running command R: estimate many cohorts event times, use command. example: detailed manual explaining various features available available running command R:","code":"varnames = list() varnames$time_name = \"year\" varnames$outcome_name = \"Y\" varnames$cohort_name = \"cohort\" varnames$id_name = \"id\" DiDge(inputdata = yourdata, varnames = varnames,              cohort_time = 2010, event_postperiod = 3) ?DiDge DiD(inputdata = yourdata, varnames = varnames,     min_event = -3, max_event = 5) ?DiD"},{"path":"https://setzler.github.io/DiDforBigData/index.html","id":"further-information","dir":"","previous_headings":"","what":"Further Information","title":"A Big Data Implementation of Difference-in-Differences Estimation with Staggered Treatment","text":"information, read following articles: Get Started Background Demonstration Theory Methods Function Documentation Detailed Examples Acknowledgements: Thanks Mert Demirer Kirill Borusyak helpful comments.","code":""},{"path":"https://setzler.github.io/DiDforBigData/reference/DiD.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine DiD estimates across cohorts and event times. — DiD","title":"Combine DiD estimates across cohorts and event times. — DiD","text":"Estimate possible cohorts event time pairs (g,e), well average across cohorts event time (e).","code":""},{"path":"https://setzler.github.io/DiDforBigData/reference/DiD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine DiD estimates across cohorts and event times. — DiD","text":"","code":"DiD(   inputdata,   varnames,   control_group = \"all\",   base_event = -1,   min_event = NULL,   max_event = NULL,   Esets = NULL,   return_ATTs_only = TRUE,   parallel_cores = 1 )"},{"path":"https://setzler.github.io/DiDforBigData/reference/DiD.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine DiD estimates across cohorts and event times. — DiD","text":"inputdata data.table. varnames list form varnames = list(id_name, time_name, outcome_name, cohort_name), four arguments list must character corresponds variable name inputdata. control_group three possibilities: control_group=\"never-treated\" uses never-treated control group ; control_group=\"future-treated\" uses units receive treatment future control group; control_group=\"\" uses never-treated future-treated control group. Default control_group=\"\". base_event base pre-period normalized zero estimation. Default base_event=-1. min_event minimum event time (e) estimate. Default NULL, case, minimum imposed. max_event maximum event time (e) estimate. Default NULL, case, maximum imposed. Esets list sets event times provided, loop sets, computing average ATT_e across event times e. Default NULL. return_ATTs_only Return ATT estimates sample sizes. Default TRUE. parallel_cores Number cores use parallel processing. greater 1, try run library(parallel), \"parallel\" package must installed. Default 1.","code":""},{"path":"https://setzler.github.io/DiDforBigData/reference/DiD.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine DiD estimates across cohorts and event times. — DiD","text":"list two components: results_cohort data.table DiDge estimates (event e cohort g), results_average data.table DiDe estimates (event e, average across cohorts g). Esets argument specified, third component called results_Esets included list output.","code":""},{"path":"https://setzler.github.io/DiDforBigData/reference/DiD.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine DiD estimates across cohorts and event times. — DiD","text":"","code":"# simulate some data simdata = SimDiD(sample_size=200, ATTcohortdiff = 2)$simdata  # define the variable names as a list() varnames = list() varnames$time_name = \"year\" varnames$outcome_name = \"Y\" varnames$cohort_name = \"cohort\" varnames$id_name = \"id\"  # estimate the ATT for all cohorts at event time 1 only DiD(simdata, varnames, min_event=1, max_event=1) #> $results_cohort #>    Cohort EventTime BaseEvent CalendarTime    ATTge  ATTge_SE Ncontrol Ntreated #> 1:   2007         1        -1         2008 1.674411 0.2372155      151       49 #> 2:   2010         1        -1         2011 4.167621 0.2547631      101       50 #> 3:   2012         1        -1         2013 5.959456 0.2787505       51       50 #>  #> $results_average #>    EventTime BaseEvent     ATTe   ATTe_SE Ncontrol Ntreated #> 1:         1        -1 3.948993 0.1535922      303      149 #>"},{"path":"https://setzler.github.io/DiDforBigData/reference/DiDge.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate DiD for a single cohort (g) and a single event time (e). — DiDge","title":"Estimate DiD for a single cohort (g) and a single event time (e). — DiDge","text":"Estimate single cohort (g) single event time (e).","code":""},{"path":"https://setzler.github.io/DiDforBigData/reference/DiDge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate DiD for a single cohort (g) and a single event time (e). — DiDge","text":"","code":"DiDge(   inputdata,   varnames,   cohort_time,   event_postperiod,   base_event = -1,   control_group = \"all\",   return_data = FALSE,   return_ATTs_only = TRUE )"},{"path":"https://setzler.github.io/DiDforBigData/reference/DiDge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate DiD for a single cohort (g) and a single event time (e). — DiDge","text":"inputdata data.table. varnames list form varnames = list(id_name, time_name, outcome_name, cohort_name), four arguments list must character corresponds variable name inputdata. cohort_time treatment cohort reference. event_postperiod Number time periods cohort time estimate . base_event base pre-period normalized zero estimation. Default base_event=-1. control_group three possibilities: control_group=\"never-treated\" uses never-treated control group ; control_group=\"future-treated\" uses units receive treatment future control group; control_group=\"\" uses never-treated future-treated control group. Default control_group=\"\". return_data true, returns treated control differenced data. Default FALSE. return_ATTs_only Return ATT estimates sample sizes. Default TRUE.","code":""},{"path":"https://setzler.github.io/DiDforBigData/reference/DiDge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate DiD for a single cohort (g) and a single event time (e). — DiDge","text":"single-row data.table() containing estimates various statistics sample size. return_data=TRUE, instead returns list data_prepost entry previously-mentioned single-row data.table(), argument data_prepost  contains constructed data provided OLS.","code":""},{"path":"https://setzler.github.io/DiDforBigData/reference/DiDge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate DiD for a single cohort (g) and a single event time (e). — DiDge","text":"","code":"# simulate some data simdata = SimDiD(sample_size=200)$simdata  # define the variable names as a list() varnames = list() varnames$time_name = \"year\" varnames$outcome_name = \"Y\" varnames$cohort_name = \"cohort\" varnames$id_name = \"id\"  # estimate the ATT for cohort 2007 at event time 1 DiDge(simdata, varnames, cohort_time=2007, event_postperiod=1) #>    Cohort EventTime BaseEvent CalendarTime    ATTge  ATTge_SE Ncontrol Ntreated #> 1:   2007         1        -1         2008 1.674411 0.2372155      151       49  # change the base period to -3 DiDge(simdata, varnames, base_event=-3, cohort_time=2007, event_postperiod=1) #>    Cohort EventTime BaseEvent CalendarTime    ATTge  ATTge_SE Ncontrol Ntreated #> 1:   2007         1        -3         2008 1.519178 0.2446772      151       49  # use only the never-treated control group DiDge(simdata, varnames, control_group = \"never-treated\", cohort_time=2007, event_postperiod=1) #>    Cohort EventTime BaseEvent CalendarTime    ATTge  ATTge_SE Ncontrol Ntreated #> 1:   2007         1        -1         2008 1.511766 0.2896609       51       49"},{"path":"https://setzler.github.io/DiDforBigData/reference/SimDiD.html","id":null,"dir":"Reference","previous_headings":"","what":"DiD data simulator with staggered treatment. — SimDiD","title":"DiD data simulator with staggered treatment. — SimDiD","text":"Simulate data model Y_it =  alpha_i + mu_t + ATT*(t >= G_i) + epsilon_it, individual, t year, G_i cohort. ATT formula ATTat0 + EventTime*ATTgrowth + \\*cohort_counter\\*ATTcohortdiff, cohort_counter order treated cohort (first, second, etc.).","code":""},{"path":"https://setzler.github.io/DiDforBigData/reference/SimDiD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DiD data simulator with staggered treatment. — SimDiD","text":"","code":"SimDiD(   seed = 1,   sample_size = 100,   cohorts = c(2007, 2010, 2012),   ATTat0 = 1,   ATTgrowth = 1,   ATTcohortdiff = 0.5,   anticipation = 0,   minyear = 2003,   maxyear = 2013,   idvar = 1,   yearvar = 1,   shockvar = 1,   indivAR1 = FALSE,   time_covars = FALSE,   clusters = FALSE,   markets = FALSE,   randomNA = FALSE,   missingCohorts = NULL )"},{"path":"https://setzler.github.io/DiDforBigData/reference/SimDiD.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DiD data simulator with staggered treatment. — SimDiD","text":"seed Set random seed. Default seed=1. sample_size Number individuals. Default sample_size=100. cohorts Vector years treatment onset occurs. Default cohorts=c(2007,2010,2012). ATTat0 Treatment effect event time 0. Default 1. ATTgrowth Increment ATT event time 0. Default 1. ATTcohortdiff Incrememnt ATT cohort. Default 0.5. anticipation Number years prior cohort allow 50% treatment effects. Default anticipation=0. minyear Minimum calendar year include data. Default minyear=2003. maxyear Maximum calendar year include data. Default maxyear=2013. idvar Variance individual fixed effects (alpha_i). Default idvar=1. yearvar Variance year effects (mu_i). Default yearvar=1. shockvar Variance idiosyncratic shocks (epsilon_it). Default shockvar=1. indivAR1 individual's shocks follow AR(1) process. Default FALSE. time_covars Add 2 time-varying covariates, called \"X1\" \"X2\". Default FALSE. clusters Add 10 randomly assigned clusters, cluster-specific AR(1) shocks. Default FALSE. markets Add 10 randomly assigned markets, market-specific shocks systematically greater markets treated earlier. Default FALSE. randomNA TRUE, randomly assign outcome variable missing values (NA) cases. Default FALSE. missingCohorts set particular cohort (vector cohorts), outcomes cohort event time -1 set missing. Default NULL.","code":""},{"path":"https://setzler.github.io/DiDforBigData/reference/SimDiD.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"DiD data simulator with staggered treatment. — SimDiD","text":"list two data.tables. first data.table simulated data variables (id, year, cohort, Y), Y outcome variable. second data.table contains true ATT values, (event,cohort) level event averaging across cohorts.","code":""},{"path":"https://setzler.github.io/DiDforBigData/reference/SimDiD.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"DiD data simulator with staggered treatment. — SimDiD","text":"","code":"# simulate data with default options SimDiD() #> $simdata #>        id year cohort         Y #>    1:   1 2003   2012  8.058406 #>    2:   1 2004   2012 12.348703 #>    3:   1 2005   2012  7.549438 #>    4:   1 2006   2012  9.731058 #>    5:   1 2007   2012 11.269052 #>   ---                           #> 1096: 100 2009   2010  7.071765 #> 1097: 100 2010   2010 12.349172 #> 1098: 100 2011   2010 13.647523 #> 1099: 100 2012   2010 13.490701 #> 1100: 100 2013   2010 12.650051 #>  #> $true_ATT #>      cohort event    ATTge #>  1:    2007     0 1.000000 #>  2:    2007     1 2.000000 #>  3:    2007     2 3.000000 #>  4:    2007     3 4.000000 #>  5:    2007     4 5.000000 #>  6:    2007     5 6.000000 #>  7:    2007     6 7.000000 #>  8:    2010     0 1.500000 #>  9:    2010     1 2.500000 #> 10:    2010     2 3.500000 #> 11:    2010     3 4.500000 #> 12:    2012     0 2.000000 #> 13:    2012     1 3.000000 #> 14: Average     0 1.506757 #> 15: Average     1 2.506757 #> 16: Average     2 3.255102 #> 17: Average     3 4.255102 #> 18: Average     4 5.000000 #> 19: Average     5 6.000000 #> 20: Average     6 7.000000 #>"},{"path":"https://setzler.github.io/DiDforBigData/news/index.html","id":"didforbigdata-10","dir":"Changelog","previous_headings":"","what":"DiDforBigData 1.0","title":"DiDforBigData 1.0","text":"CRAN release: 2023-04-03 Published CRAN. install.packages(\"DiDforBigData\") now works.","code":""},{"path":"https://setzler.github.io/DiDforBigData/news/index.html","id":"didforbigdata-03","dir":"Changelog","previous_headings":"","what":"DiDforBigData 0.3","title":"DiDforBigData 0.3","text":"First public release. Add progress bar predict long estimation take. Simplify package 3 functions: , DiDge, SimDiD.","code":""},{"path":"https://setzler.github.io/DiDforBigData/news/index.html","id":"didforbigdata-02","dir":"Changelog","previous_headings":"","what":"DiDforBigData 0.2","title":"DiDforBigData 0.2","text":"Add support robust clustered standard errors. Add support high-dimensional fixed-effect covariates.","code":""},{"path":"https://setzler.github.io/DiDforBigData/news/index.html","id":"didforbigdata-01","dir":"Changelog","previous_headings":"","what":"DiDforBigData 0.1","title":"DiDforBigData 0.1","text":"Add support time-varying covariates. Initialize simple estimation framework.","code":""}]
